---
title: "Tarea 2 Simulación"
author: "Bernardo Mondraón Brozon"
date: "4 de septiembre de 2018"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
library(latex2exp)
library(ggplot2)
```

# Problema 1

Probar por inducción matemática que para un GLC,
$$Z_i=a^iZ_0+c\frac{a^i-1}{a-1}\quad \mathrm{mod} \quad m$$

\textbf{Demostración:}

Para $i=0$ se tiene que
$$\begin{aligned}
  Z_0 &= Z_0 \quad \mathrm{mod} \quad m  \\
            &= a^0Z_0+c\frac{a^0-1}{a-1} \quad \mathrm{mod} \quad m,
\end{aligned}$$

y para $i=1$ se tiene que
$$\begin{aligned}
  Z_1 &= aZ_0 + c  \quad \mathrm{mod} \quad m  \\
      &= a^1Z_0+c\frac{a^1-1}{a-1} \quad \mathrm{mod} \quad m.
\end{aligned}$$

Procediendo por indución, se supone válido para $i$ de manera que 
$$\begin{aligned}
  Z_{i+1} &= aZ_i + c  \quad \mathrm{mod} \quad m  \\
      &= a\left(a^iZ_0+c\frac{a^i-1}{a-1}\right)+c \quad \mathrm{mod} \quad m \\
      &= a^{i+1}Z_0+c\frac{a^{i+1}-1}{a-1} \quad \mathrm{mod} \quad m. \\
\end{aligned}$$

Por lo tanto es váido para toda $i\in\mathbb{N}$.

\begin{flushright}
$\blacksquare$
\end{flushright}

# Problema 2

¿Qué se puede decir del periodo de $Z_i=630,360,016Z_{i-1} \quad \mathrm{mod} \quad 2^{31}-1$?

\textbf{Solución:}

Se puede decir que su periodo es inferor a $2^{31}-1$.

# Problema 3

Sin calcular ninguna $Z_i$, determinar cuál de los siguientes GLC’s mixtos tienen periodo completo. 

\begin{itemize}
\item[a)] $Z_i=13Z_{i-1} + 13 \quad \mathrm{mod} \quad 16$.
\item[b)] $Z_i=12Z_{i-1} + 13 \quad \mathrm{mod} \quad 16$.
\item[c)] $Z_i=13Z_{i-1} + 12 \quad \mathrm{mod} \quad 16$.
\item[d)] $Z_i=Z_{i-1} + 12 \quad \mathrm{mod} \quad 13$.
\item[e)] El GLC con pará metros: $a=2,814,749,767,109$, $c=59,482,661,568,307$, $m=248$.
\end{itemize}

\textbf{Solución:}

```{r, warning=FALSE, message=FALSE}
#install.packages("numbers")
library(numbers)
#install.packages("gmp")
library(gmp)
check <- function(a, c, m) {
  condition1Holds <- coprime(c,m)
  # Descomponer en factores primos a m
  primes <- factorize(m)
  condition2Holds <- FALSE
  # Check if any prime factor also divides a-1
  for (i in 1:length(primes)) {
    if (a %% primes[i] == 1) {
      condition2Holds <- TRUE
      break
    }
  }
  condition3Holds <- TRUE
  if (m %% 4 == 0) {
    if (!a %% 4 == 1) {
      condition3Holds <- FALSE
    } 
  }
  #return(condition1Holds && condition2Holds && condition3Holds)
  if (condition1Holds && condition2Holds && condition3Holds) {
    return("El generador lineal congruencial tiene periodo completo")
    #return(TRUE)
  } else {
    return("El generador lineal congruencial no tiene periodo completo")
    #return(FALSE)
  }
}
```

\begin{itemize}
\item[a)] $Z_i=13Z_{i-1} + 13 \quad \mathrm{mod} \quad 16$.
\end{itemize}

`r check(13,13,16)`

\begin{itemize}
\item[b)] $Z_i=12Z_{i-1} + 13 \quad \mathrm{mod} \quad 16$.
\end{itemize}

`r check(12,13,16)`

\begin{itemize}
\item[c)] $Z_i=13Z_{i-1} + 12 \quad \mathrm{mod} \quad 16$.
\end{itemize}

`r check(13,12,16)`

\begin{itemize}
\item[d)] $Z_i=Z_{i-1} + 12 \quad \mathrm{mod} \quad 13$.
\end{itemize}

`r check(1,12,13)`

\begin{itemize}
\item[e)] El GLC con pará metros: $a=2,814,749,767,109$, $c=59,482,661,568,307$, $m=248$.
\end{itemize}

`r check(2814749767109,59482661568307,248)`

# Problema 4

Mostrar que el promedio de las $U_i$’s tomadas de un ciclo completo de un GLC de periodo completo es $\frac{1}{2}-\frac{1}{2m}$.

# Problema 5

Generar 10,000 números uniformemente distribuidos entre 0 y 1 en Excel. Hacer un breve estudio para probar la calidad de los generadores; aplicar las pruebas de uniformidad e independencia a cada conjunto de datos. Resumir resultados en NO MAS de 2 cuartillas, incluyendo gráficas. De acuerdo a tus resultados, ¿cómo calificarías al generador de Excel?

\textbf{Solución:}

## Pruebas de bondad de ajuste

```{r}
df = read.csv("../uniformNumbers.csv", sep="", header = TRUE)
unifs <- df$Unif
```

A continuación se muestra la gráfica de la distribución empírica de los valores generados con Excel y la gráfica de la distribución uniforme en el intervalo $[0,1]$:

```{r, fig.width=4, fig.height=3, fig.align = "center"}
labels <- c("Empírica", "Teórica")
ggplot() +
  stat_function(data=data.frame(type="2"), 
                fun = function(x) x, 
                size=1.2, 
                aes(1, group=type, color=type, linetype=type)) +
  stat_ecdf(data=data.frame(unifs, type="1"),
            geom = "step", 
            aes(unifs, group=type,  color=type, linetype=type)) +
  ggtitle("Teórica vs empírica") +
  labs(x=TeX("x"), y=TeX("F_n(x) & F(x)")) +
  theme(plot.title = element_text(hjust = 0.5)) +
  scale_colour_manual(
    values=c("green", "black"),
    labels = labels
  ) + 
  scale_linetype_manual(
    values = c(1,6),
    labels = labels
  ) +
  scale_size_manual(
    values = c(1,2),
    labels = labels
  )
```

Se realizará la prueba de Kolmogorov-Smirnov (prueba de bondad de ajuste) a los valores simulados para determinar si efectivamente provienen de la distribucion uniforme en el intervalo $[0,1]$. Para realizar la prueba se contrastaran las siguientes hipótesis:
$$H_0:F(x)=x\quad \forall x \quad \mathrm{vs.} \quad H_1:F(x)\neq x \quad \mathrm{para} \; \mathrm{alguna} \; x $$
Entonces la estadística de prueba está dada por 
$$ D_n=\max_x{|F_n(x)-x|}. $$
Se rechazará la hipótesis $H_0$ si $D_n$ es muy grande. En este caso, la estadística de prueba toma el siguiente valor

```{r}
unif_ord <- sort(unifs, decreasing = FALSE)
Dp <- max(1:length(unif_ord)/length(unif_ord)-unif_ord)
Dm <- max(unif_ord-0:(length(unif_ord)-1)/length(unif_ord))
Dmax <- max(Dp,Dm)
```

$$D_n = `r Dmax`$$

El valor p correspondiente al valor de la estadística de prueba está dado por 

```{r}
pval <- 2*exp(-2*length(unif_ord)*Dmax^2)
```

$$\textrm{p-value} = `r pval`$$
En este caso el valor p es mayor a 1 porque se calculó mediante una aproximación, sin embargo el verdadero valor es muy cercano a 1, de manera que no se rechaza la hipótesis de que los números aleatorios provienen de la distribución uniforme.

```{r}
#install.packages("goftest")
library(goftest)
CvMtest <- cvm.test(unifs, null = "punif")
CvMtestStatistic <- CvMtest$statistic
CvMpVal <- CvMtest$p.value
```


Aplicando la prueba de Crámer-von Misses se obtiene el siguiente valor de la estadística de prueba:

$$W_n=n\int_{-\infty}^{\infty}\left(F_n(x)-F(x)\right)^2\mathrm{d}F(x)=10000\int_{-\infty}^{\infty}\left(F_n(x)-x\right)^2\mathrm{d}x=`r CvMtestStatistic`.$$

De manera que el valor p está dado por 

$$\textrm{p-value} = `r CvMpVal`$$

```{r}
ADtest <- ad.test(unifs, null = "punif")
ADtestStatistic <- ADtest$statistic
ADpVal <- ADtest$p.value
```


Aplicando la prueba de Anderson-Darling se obtiene el siguiente valor de la estadística de prueba:

$$A^2_n=n\int_{-\infty}^{\infty}\frac{\left(F_n(x)-F(x)\right)^2}{F(x)\left(1-F(x)\right)}\mathrm{d}F(x)=10000\int_{-\infty}^{\infty}\frac{\left(F_n(x)-x\right)^2}{x\left(1-x\right)}\mathrm{d}x=`r ADtestStatistic`$$

De manera que el valor p está dado por 

$$\textrm{p-value} = `r ADpVal`$$

A continuación se muestra el histograma de los datos generados en Excel y la función de densidad uniforme en el intervalo $[0,1]$:

```{r, fig.width=4, fig.height=3, fig.align = "center"}
breaks <- seq(0, 1, by=.1)
ggplot() +
  geom_histogram(data=df, aes(x=df$Unif, y=..density..), breaks=breaks, color="green", fill="green", alpha=.2) +
  stat_function(fun=function(x) {1}, color="black", aes(1)) +
  labs(x = TeX("x"), y = TeX('Frecuencia, f(x)')) +
  ggtitle("Histograma vs. Densidad") +
  theme(plot.title = element_text(hjust = 0.5)) +
  ylim(0,2)
```

```{r}
prueba.chisq.uniforme <- function(x, k = ceiling(length(x)/5)) {
  n <- length(x)
  part <- seq(0, 1, length = k + 1) #partición 
  z <- hist(x, breaks = part, plot = F)$counts 
  ch <- (k/n)*sum((z-n/k)^2) #estadística chi 
  pval <- pchisq(ch, k - 1, lower.tail = F) 
  return(list(part = part, freqs = z, estadistica = ch, pval = pval))
}
chiTest <- prueba.chisq.uniforme(unifs, ceiling(length(unifs)/5))
chi <- chiTest[[3]]
chi.pval <- chiTest[[4]]
```


Para la prueba de bondad de ajuste $\chi^2$ de Pearson, las hipótesis a contrastar son las mismas que las de la prueba de Kolmogorov-Smirnov En este caso la estadistica de prueba toma el siguinete valor:

$$\chi^2=\sum_{i=1}^{k}\frac{(N_j-np_j)^2}{np_j}=\sum_{i=1}^{`r length(chiTest[2])`}\frac{(N_j-10000p_j)^2}{10000p_j}=`r chi`$$

De manera que el valor p está dado por 

$$\textrm{p-value} = `r chi.pval`$$

Por lo tanto no se rechaza la hipótesis nula de que los datos generados por Excel provienen de la distribución uniforme en el intervalo $[0,1]$.

A continuación se presenta un qq-plot de lo valores generados por Excel.
Si el qq'plot sigue la recta identidad cuando se grafica contra la distribución teórica, entonces se puede decir que los datos siguien adecuadamente la distribución uniforme en el intervalo $[0,1]$.

```{r, fig.width=4, fig.height=3, fig.align = "center"}
ggplot(data=df, aes(sample=Unif)) +
  stat_qq(distribution = qunif) +
  stat_function(fun=function(x) x, size=1, color = "green", aes(seq(0,1,10000))) +
  xlim(c(0,1)) +
  ylim(c(0,1)) +
  labs(x = TeX("Teóricos"), y = TeX("Muestrales")) +
  ggtitle("QQ-Plot") +
  theme(plot.title = element_text(hjust = 0.5))
```

Al parecer se tiene un buen ajuste, sin embargo, esto no es una prueba en sentido estricto; es simplemente una guía visual para determinar si se tiene un buen ajuste.

## Pruebas de independencia

Aplicando la prueba de independencia que utiliza a las rachas en la sucesión de números aleatorios se obtiene el siguiente número de rechas:

```{r}
nrachas <- function(x) {
  n <- length(x)
  signo <- x[-1] - x[-n] 
  s <- ifelse(signo<0,-1,1)
  R <- 1 + sum(s[-1] != s[-(n-1)]) #cuenta los cambios de signo 
  return(R)
}
R <- nrachas(unifs)
```


$$ R=`r R`$$

```{r}
Z <- (R-(2*length(unifs)-1)/3)/sqrt((16*R-29)/90)
```


Mediante la aproximación normal se tiene el siguiente valor del estadístico de prueba que sigue la distribucion normal estandar:
$$Z=\frac{R-(2n-1)/3}{\sqrt(\left(16R-29)/90\right)}=`r Z`.$$

El correspondiente valor p para el valor dado de la estadística de prueba está dado por

$$\textrm{p-value}=`r pnorm(Z)`$$

```{r}
prueba.rachas <- function(x) { 
  a <- matrix(c(4529.4, 9044.9, 13568, 18091, 22615, 27892, 9044.9, 18097, 27139, 36187, 45234, 55789, 13568, 27139, 40721, 54281, 67852, 83685, 18091, 36187, 54281, 72414, 90470, 111580, 22615, 45234, 67852, 90470, 113262, 139476, 27892, 55789, 83685, 111580, 139476, 172860), nrow = 6) 
  b <- c(1/6,5/24,11/120,19/720,29/5040,1/840) 
  n <- length(x) 
  x1 <- c(1) #inicializa el indicador de cambios de signo 
  x1[2:length(x)] <- sign(diff(x)) #guardamos los cambios de signos de la muestra 
  cambios <- c((1:length(x1))[x1==-1],length(x)+1) #contamos los cambios de signo 
  tabla <- table(c(cambios[1]-1,diff(cambios)),exclude=NULL) 
  aa <- tabla[match(1:length(x),as.numeric(names(tabla)))] 
  aa <- ifelse(is.na(aa),0,aa) 
  aa[6] <- sum(aa[6:n]) #agrupa el número de rachas de longitud 6 o más 
  r <- aa[1:6] 
  names(r) <- c(1:5,">=6") 
  R <- as.numeric((r-n*b)%*%a%*%t(t((r-n*b)))/n) #Estadística de Levene-Wolfowitz
  return(list(x=head(x,10),R=R,r=r,pval=pchisq(R,6,lower.tail=F))) 
}
rachas.test <- prueba.rachas(unifs)
est.test <- rachas.test$R
.est.test.p.val <- rachas.test$pval
```


Aplicando la prueba de independencia de Levene-Wolfowitz se obtiene el siguiente valor para la estadística de prueba:

$$R_n=`r est.test`.$$

El correspondiente valor p para el valor dado de la estadística de prueba está dado por

$$\textrm{p-value}=`r .est.test.p.val`$$

```{r, results='hide', warning=FALSE, message=FALSE}
library(randtoolbox)
gap.testB <- gap.test(unifs)
stat <- gap.testB$statistic
p.val.gaps <- gap.testB$p.value
```

Aplicando la prueba de gaps se obtiene el siguiente valor para la estadística de prueba:

$$R_n=`r stat`.$$

El correspondiente valor p para el valor dado de la estadística de prueba está dado por

$$\textrm{p-value}=`r p.val.gaps`$$

```{r, message=FALSE, warning=FALSE}
separa <- function(x) { 
  #separa un número en sus dígitos componentes. 
  w <- substring(as.character(x),3) 
  if (nchar(w) < 4) for(i in 1:(4-nchar(w))) w <- paste(w, "0", sep = "")
  return(as.numeric(unlist(strsplit(w,"")))) 
}

tabla <- function(x,k) { 
  # Hace una tabla de frecuencias de cada dígito 
  tabla <- table(x) 
  aa <- tabla[match(0:(k-1),as.numeric(names(tabla)))] 
  aa <- ifelse(is.na(aa),0,aa) 
  r <- aa[1:k] 
  names(r) <- 0:(k-1) 
  return(r) 
}

prueba.poker<-function(vec) { 
  z <- round(vec,4) #redondeo a 4 decimales 
  N <- length(z) #apaga los warnings por un momento 
  ow <- options("warn") 
  options(warn = -1) 
  dim(z) <- c(N,1) #convierte el vector de datos a una matriz columna 
  z1 <- apply(z, 1, separa) #separa cada numero aleatorio en los componentes 
  z2 <- t(apply(z1, 2, tabla, k=10)) #crea una tabla de frecuencias 
  # z3<-matrix(unlist(z2),nrow=N,ncol=10,byrow=T) #crea matriz de frecuencias para digitos 
  # frecuencias de ceros unos, dos y tres de la tabla de frecuencias anterior, 
  # para caracterizar los posibles juegos en cada "mano": 
  # pachuca: hay 6 ceros y 4 unos siempre. 
  # un par : hay 7 ceros y 1 dos y 2 unos. 
  # dos pares: hay 2 dos, 8 ceros 
  # una tercia: hay 1 tres y 1 uno, 8 ceros 
  # un pokar: hay 1 cuatro y 9 ceros 
  z1 <- apply(z2, 1, table) 
  pachuca <- sum(unlist(lapply(z1,function(x){ifelse(x[1]==6,1,0)}))) 
  unpar <- sum(unlist(lapply(z1,function(x){ifelse(x[1]==7,1,0)}))) 
  dospar <- sum(unlist(lapply(z1,function(x){ifelse((x[1]==8)&(x[2]==2),1,0)}))) 
  tercia <- sum(unlist(lapply(z1,function(x){ifelse((x[1]==8)&(length(x)==3),1,0)}))) 
  pokar <- sum(unlist(lapply(z1,function(x){ifelse(x[1]==9,1,0)}))) 
  #obs<-apply(z3,2,sum) #suma por columna 
  esp <- N*c(0.504, 0.432, 0.027, 0.036, 0.001) 
  obs <- c(pachuca, unpar, dospar, tercia, pokar) 
  prueba <- sum((obs-esp)^2/esp) 
  pval <- 1 - pchisq(prueba,4) 
  #names(obs) <- 0:9 
  options(ow) 
  return(list(cbind(Esperado=esp,Observado=obs),Estadistica=prueba,pval=round(pval,5)))
}
probonsia <- prueba.poker(unifs)
pokar.est <- probonsia$Estadistica
pokar.pval <- probonsia$pval
```


Aplicando la prueba del poker se obtiene el siguiente valor para la estadística de prueba:

$$R_n=`r pokar.est`.$$

El correspondiente valor p para el valor dado de la estadística de prueba está dado por

$$\textrm{p-value}=`r pokar.pval`$$

Aplicando pruebas de autocorrelacion, se obitnene los siguiente:

```{r}
#Prueba de Barttlet: 
rho1 <- acf(unifs,1,plot=F)$acf[2] 
bt <- sqrt(length(unifs))*rho1 
1-pnorm(bt)/2 #p-value

#Prueba de Box-Pierce: 
Box.test(unifs,lag=3,type="Box-Pierce")

#Prueba de Lgung-Box: 
Box.test(unifs,lag=3,type="Ljung-Box")
```
De acuerdo a las pruebas anteriores, se puede concluir que el generador de números aleatorios de excel es un buen generador de números aleatorios. De manera que no se rechaza la hipótesis de que los números son independientes.

# Problema 6 

Probar que la parte fraccional de la suma de uniformes en $[0,1]$: $U1+\cdots+U_k$ es también uniforme en el intervalo $[0,1]$.

\textbf{Solución:}

Sea $\{x\}=x-\lfloor x\rfloor$ la parte fraccional del número $x$, y $S_k=\sum_{i=1}^kU_i$ la suma de $k$ variables aleatorias independientes e uniformemente distribuidas en el intervalo $[0,1]$. Para $k=1$ se tiene que $\{S_1\}=\{U_1\}=U_1\sim U[0,1]$. Para $k=2$ se tiene que $\{S_2\}=\{U_1+U_2\}$ con 

$$
f_{S_2}(s) = \left\{
        \begin{array}{ll}
            s & \quad 0 \leq s \leq 1 \\
            2-s & \quad 1 < s \leq 2
        \end{array}.
    \right.
$$
de manera que 

$$\begin{aligned}
  F_{\{S_2\}}(x) &= Pr\left[\{S_2\}\leq x\right]  \\
      &= \int_{u=0}^s f_{S_2}(u) \, du + \int_{u=1}^{1+s} f_{S_2}(u) \, du = s. \\
\end{aligned}$$

Entonces $\{S_2\}$ sigue la distribución uniforme en el intervalo $[0,1]$. Procediendo mediante inducción se supone válido para $k$, de manera que 
$$\{S_k\}\sim U[0,1].$$

Por lo tanto, para $k+1$ se tiene que 
$$\{S_{k+1}\}=\{U_1+\cdots+U_{k+1}\}=\{\{U_1+\cdots+U_k\}+U_{k+1}\}=\{\{S_k\}+U_{k+1}\}.$$
Pero $\{S_k\}$ y $U_{k+1}$ tienen la distribución uniforme y son independientes, entonces 
$$\{S_{k+1}\}\sim U[0,1].$$
